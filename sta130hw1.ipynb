{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67eb0817",
   "metadata": {},
   "source": [
    "STA130 HOMEWORK ONE - EVELYN JIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e36fb",
   "metadata": {},
   "source": [
    "PART ONE: PRELECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae267a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a4178",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952422e8",
   "metadata": {},
   "source": [
    "PART TWO: PRELECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6360f",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b14d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (observations): 391\n",
      "Number of columns (variables): 11\n",
      "Column names: ['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality', 'song', 'phrase', 'full_id', 'url']\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of rows (observations): {num_rows}\")\n",
    "print(f\"Number of columns (variables): {num_columns}\")\n",
    "\n",
    "# Optionally, print column names\n",
    "print(f\"Column names: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46956fa0",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc2c2e",
   "metadata": {},
   "source": [
    "Observations (Rows):\n",
    "In the context of the dataset, an observation corresponds to a unique villager. Each row represents an individual character.\n",
    "\n",
    "Variables (Columns):\n",
    "A variable is an attribute recorded for each observation (villager). Each column in the DataFrame represents a distinct characteristic such as their name, birthday, species, or personality type. These variables describe the individual traits of each villager."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a6b58",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ff304",
   "metadata": {},
   "source": [
    "PART THREE: PRELECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd828cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Numeric Columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Value Counts for 'species' Column:\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'personality' Column:\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'villagers.csv' with the correct path)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')\n",
    "\n",
    "# 1. Display basic summary statistics for numeric columns\n",
    "print(\"Summary Statistics for Numeric Columns:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 2. Show unique value counts for categorical columns\n",
    "# Example for the 'species' column (you can replace 'species' with other categorical columns)\n",
    "print(\"\\nValue Counts for 'species' Column:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# 3. If you want summaries for more categorical columns, do the same for other columns:\n",
    "# Value counts for 'personality'\n",
    "print(\"\\nValue Counts for 'personality' Column:\")\n",
    "print(df['personality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220bcdc6",
   "metadata": {},
   "source": [
    "The .describe() method provides summary statistics for numeric columns in your dataset, such as the count, mean, standard deviation, minimum, and maximum values.\n",
    "\n",
    "The .value_counts() method gives you a count of unique values for categorical columns. For example, .value_counts(personality) will show how many villagers belong to each personality. It can work for any other categorical column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb30c71",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881bfea",
   "metadata": {},
   "source": [
    "PART FOUR: PRELECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf6d1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\")\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Check the basic summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25388a",
   "metadata": {},
   "source": [
    "The df.shape function returns a tuple (number_of_rows, number_of_columns). This tells you the total size of the dataset. The output tells you that there are 891 rows (observations) and 15 columns (variables).\n",
    "\n",
    "a) Number of Columns Analyzed\n",
    "\n",
    "df.shape reports 15 columns (the total number of variables). df.describe() reports only the numeric columns, typically fewer than 15. df.describe() automatically excludes non-numeric columns (like sex, embarked, who, deck, etc.). in this dataset, only numeric columns like survived, pclass, age, sibsp, parch, and fare are included in the summary statistics.\n",
    "\n",
    "(b) Values Reported in the \"count\" Column:\n",
    "\n",
    "The \"count\" column in df.describe() reports how many non-missing values (i.e., non-NaN values) are present for each numeric column. Discrepancy in \"count\" values occur since missing values cause discrepancies. For example, in the age column, df.shape shows that the dataset has 891 rows, but the count for age is 714. This means there are 177 missing values (NaN) in the age column. The age column has a count of 714, meaning there are 714 non-missing values and 177 missing (NaN) values. Other columns like pclass, survived, and fare have no missing values and show a count of 891.\n",
    "\n",
    "The differences occur because non-numeric columns such as df.describe() only analyzes numeric data by default, so columns like sex, embarked, deck, etc., which are categorical, are excluded from the analysis. It also happens because of missing values like the \"count\" in df.describe() reflects the number of non-missing values for each column. If there are missing values (like in the age column), the count will be lower than the total number of rows (which df.shape gives you)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab68650",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef84230",
   "metadata": {},
   "source": [
    "PART FIVE: PRELECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b37eb7",
   "metadata": {},
   "source": [
    "Attributes vs. Methods\n",
    "\n",
    "Attributes are properties associated with an object. They do not have parentheses because they are simply values or states of the object. You access attributes directly, like df.shape to get the shape of the DataFrame.\n",
    "\n",
    "Methods are functions that belong to an object. They perform actions on the object and are called using parentheses. You call methods to perform operations, like df.describe() to get a statistical summary of numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c619ea1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d2881",
   "metadata": {},
   "source": [
    "PART SIX: POSTLECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f22cb",
   "metadata": {},
   "source": [
    "These statistics provide a comprehensive summary of the distribution and spread of the numeric data in each column. Here are brief definitions of each.\n",
    "\n",
    "Count: The number of non-missing values in the column. It indicates how many values were present for that particular variable.\n",
    "\n",
    "Mean: The average value of the column. It is calculated by summing all the values in the column and then dividing by the count of non-missing values.\n",
    "\n",
    "Std (Standard Deviation): A measure of the amount of variation or dispersion in the column's values. A high standard deviation indicates that values are spread out over a wider range, while a low standard deviation indicates that values are closer to the mean.\n",
    "\n",
    "Min (Minimum): The smallest value in the column. It represents the lowest boundary of the data range.\n",
    "\n",
    "25% (25th Percentile or First Quartile): The value below which 25% of the data falls. It’s a measure of the lower boundary of the middle 50% of the data.\n",
    "\n",
    "50% (50th Percentile or Median): The middle value of the column when the data is sorted in ascending order. It divides the data into two equal halves.\n",
    "\n",
    "75% (75th Percentile or Third Quartile): The value below which 75% of the data falls. It’s a measure of the upper boundary of the middle 50% of the data.\n",
    "\n",
    "Max (Maximum): The largest value in the column. It represents the upper boundary of the data range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae6227",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d8d21",
   "metadata": {},
   "source": [
    "PART SEVEN: POSTLECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da1661",
   "metadata": {},
   "source": [
    "The Titanic dataset typically contains columns like:\n",
    "\n",
    "pclass: Passenger class\n",
    "\n",
    "sex: Gender\n",
    "\n",
    "age: Age\n",
    "\n",
    "sibsp: Number of siblings/spouses aboard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cfb8d",
   "metadata": {},
   "source": [
    "7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c941ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any missing values\n",
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e491c4",
   "metadata": {},
   "source": [
    "We use df.dropna() to ensure that our analysis includes all the data without removing columns but it focuses only on complete rows.\n",
    "\n",
    "An example could be using it to analyze survival rates based on age, sex, and fare, and there are rows with missing values in age and fare. Using df.dropna() will allow us to analyze the complete data without removing columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5415349",
   "metadata": {},
   "source": [
    "7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375602fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'embarked' column due to high missing data\n",
    "del df['embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108d721",
   "metadata": {},
   "source": [
    "We can use del df['col'] when a column has a significant amount of missing data that is crucial for our analysis. This would remove the column entirely. For example, if we wanted to analyze the embarked column, which represents the port of embarkation, we would focus on survival rates and not on embarkation details given the large amount of missing data and so del df['col'] would be the preferred method for a column that is not central to the main goal of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ec8d9",
   "metadata": {},
   "source": [
    "7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774398b",
   "metadata": {},
   "source": [
    "Applying del df['col'] before df.dropna() is important since removing columns with excessive missing data first prevents them from affecting the row removal process. This allows df.dropna() to remove non-essential columns, which improves efficiency and accuracy, while also preventing unnecessary row deletions based on columns that were not valuable or had too many missing values to begin. This then allows the cleaning up of the remaining data, ensuring that only relevant data is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a84d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61ec77",
   "metadata": {},
   "source": [
    "7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d255920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (891, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Check initial shape\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14f7aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (182, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182 entries, 1 to 889\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     182 non-null    int64  \n",
      " 1   pclass       182 non-null    int64  \n",
      " 2   sex          182 non-null    object \n",
      " 3   age          182 non-null    float64\n",
      " 4   sibsp        182 non-null    int64  \n",
      " 5   parch        182 non-null    int64  \n",
      " 6   fare         182 non-null    float64\n",
      " 7   class        182 non-null    object \n",
      " 8   who          182 non-null    object \n",
      " 9   adult_male   182 non-null    bool   \n",
      " 10  deck         182 non-null    object \n",
      " 11  embark_town  182 non-null    object \n",
      " 12  alive        182 non-null    object \n",
      " 13  alone        182 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(6)\n",
      "memory usage: 18.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove the 'embarked' column\n",
    "del df['embarked']\n",
    "\n",
    "# Remove rows with any remaining missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check the shape of the cleaned DataFrame\n",
    "print(\"Cleaned shape:\", df_cleaned.shape)\n",
    "print(df_cleaned.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e8a2b",
   "metadata": {},
   "source": [
    "Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf71bdb",
   "metadata": {},
   "source": [
    "Before: The dataset includes all columns with some having missing data. Assume the embarked column is so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc6b7d",
   "metadata": {},
   "source": [
    "Initial shape: (714, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b23a9a",
   "metadata": {},
   "source": [
    "After: Dataset is cleaned by removing less important columns with high amounts of missing data and then deleting rows with any remaining missing values. This ensures an analysis based on relevant AND complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e57f2",
   "metadata": {},
   "source": [
    "Cleaned shape: (714, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04addf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a130b6",
   "metadata": {},
   "source": [
    "PART EIGHT: POSTLECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb4c07",
   "metadata": {},
   "source": [
    "8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c086a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773c778",
   "metadata": {},
   "source": [
    "print(df.columns)  # To get the names of the columns\n",
    "print(df.head())   # To see the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f7222",
   "metadata": {},
   "source": [
    "The groupby function splits the data into groups based on some criteria. Then, the describe() method provides summary statistics for the data in each group:\n",
    "\n",
    "df.groupby(\"col1\"): Groups the data by the values in col1.\n",
    "\n",
    "[\"col2\"]: Selects the col2 column from the grouped data.\n",
    "\n",
    ".describe(): Computes summary statistics for each group in col2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb38534",
   "metadata": {},
   "source": [
    "EXAMPLE WITH THIS DATASET\n",
    "\n",
    "Let's analyze the age column grouped by the class column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcec8d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "group_by_class = df.groupby(\"class\")[\"age\"].describe()\n",
    "print(group_by_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035976a4",
   "metadata": {},
   "source": [
    "The result of df.groupby(\"class\")[\"age\"].describe() provides a summary statistics for the age column, broken down by each class (e.g., First, Second, Third), including metrics like count, mean, standard deviation, minimum, and various percentiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e37374",
   "metadata": {},
   "source": [
    "8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52263fdc",
   "metadata": {},
   "source": [
    "df.describe() provides summary statistics for each numeric column in the DataFrame.\n",
    "\n",
    "The count value in df.describe() represents the number of non-missing (non-NaN) values for each column across the entire DataFrame. It essentially tells you how many data points are available for each column, excluding any missing values. \n",
    "\n",
    "For example, if df has 1000 rows but some columns have missing values, the count of rows (data points) for those columns will be less than 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda5f75",
   "metadata": {},
   "source": [
    "df.groupby(\"col1\")[\"col2\"].describe() provides summary statistics for col2 within each group defined by col1.\n",
    "\n",
    "The count value here represents the number of non-missing values within each group defined by col1. Each group might have a different number of non-missing values depending on the distribution of missing data in col2 within that group.\n",
    "\n",
    "For example, (df.groupby(\"class\")[\"age\"].describe()) shows summary statistics for age within each class, including how many non-missing values (count) are present in each class group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210843a",
   "metadata": {},
   "source": [
    "These two functions capture different views of the dataset. While df.describe() provides a high-level view of missing data across the entire dataset, df.groupby(\"col1\")[\"col2\"].describe() provides a more granular view, showing how missing data and summary statistics differ by subgroup. This can be crucial for understanding patterns and discrepancies within different categories of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77abd9",
   "metadata": {},
   "source": [
    "8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bda3d5",
   "metadata": {},
   "source": [
    "After trying out the errors that occur, I think that ChatGPT works better than a Google Search. This is because the chatbot essentially does the same thing as a google search except it removes the task of needing to sift through each search result that appears. The chatbot seems to provide multiple solutions from multiple sources more efficiently and quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "PART NINE: POST LECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273f28c",
   "metadata": {},
   "source": [
    "Yes, mostly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782b547",
   "metadata": {},
   "source": [
    "CHATLOGS:\n",
    "\n",
    "https://chatgpt.com/share/ad56da47-1cee-489a-97dd-73c83a01c0c5\n",
    "\n",
    "https://chatgpt.com/share/109ba76a-b6bb-44ae-9ce0-73492c3579a3\n",
    "\n",
    "https://chatgpt.com/share/9c4c0e6e-0a0a-44c6-bb32-95b334dffb6a\n",
    "\n",
    "BRIEF SUMMARY:\n",
    "\n",
    "1. **Difference Between Attributes and Methods**:\n",
    "   - **Attributes** are properties of an object, accessed directly (e.g., `df.shape`).\n",
    "   - **Methods** are functions that perform actions on the object and require parentheses to execute (e.g., `df.describe()`).\n",
    "\n",
    "2. **Functions in Programming vs. Mathematics**:\n",
    "   - **Programming Functions**: Execute code to perform operations or calculations.\n",
    "   - **Mathematical Functions**: Define relationships between variables.\n",
    "\n",
    "3. **Summary Statistics from `df.describe()`**:\n",
    "   - **Count**: Number of non-missing values.\n",
    "   - **Mean**: Average value.\n",
    "   - **Std**: Standard deviation, measure of spread.\n",
    "   - **Min**: Minimum value.\n",
    "   - **25%**: 25th percentile.\n",
    "   - **50%**: Median (50th percentile).\n",
    "   - **75%**: 75th percentile.\n",
    "   - **Max**: Maximum value.\n",
    "\n",
    "4. **Handling Missing Data**:\n",
    "   - **`df.dropna()`**: Removes rows with any missing values. Useful when you want to retain columns but need complete rows for analysis.\n",
    "   - **`del df['col']`**: Removes a column, useful when the column has excessive missing data or is irrelevant.\n",
    "   - **Combining**: Remove columns first to simplify data and then drop rows to clean up the remaining data.\n",
    "\n",
    "5. **Application to Titanic Dataset**:\n",
    "   - Demonstrated removing a column with high missing data (`embarked`) and then dropping rows with remaining missing values.\n",
    "   - The dataset was cleaned to ensure only complete records were used, improving the quality of the analysis.\n",
    "   \n",
    "6. **Analyzing Titanic Data**:\n",
    "   - You started by exploring how to use a ChatBot to troubleshoot code with the Titanic dataset.\n",
    "   - You learned about the `df.groupby(\"col1\")[\"col2\"].describe()` function, which groups data by a column and then provides summary statistics for another column within each group.\n",
    "\n",
    "7. **Understanding `df.groupby(\"col1\")[\"col2\"].describe()`**:\n",
    "   - This function groups data by `col1`, selects `col2`, and then applies `describe()` to get summary statistics for `col2` within each group.\n",
    "   - Example provided: Analyzing the `age` column grouped by the `class` column.\n",
    "\n",
    "8. **Handling Missing Values**:\n",
    "   - **`df.describe()`**: Shows summary statistics for each column in the entire DataFrame, with `count` indicating the number of non-missing values across the dataset.\n",
    "   - **`df.groupby(\"col1\")[\"col2\"].describe()`**: Shows summary statistics for `col2` within each group defined by `col1`, with `count` indicating non-missing values within each group.\n",
    "\n",
    "9. **Key Differences**:\n",
    "   - **Scope of Counting**: `df.describe()` covers the entire DataFrame, while `df.groupby(\"col1\")[\"col2\"].describe()` is specific to each group.\n",
    "   - **Purpose**: `df.describe()` provides a broad overview, while `df.groupby(\"col1\")[\"col2\"].describe()` offers detailed insights into subgroup-specific patterns.\n",
    "\n",
    "This summary captures the key points of our discussion on analyzing the Titanic dataset and understanding how different methods handle missing values and provide insights. There was also the additional trouble shooting that was discussed during the process of this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192ff71",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec5d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a766093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
